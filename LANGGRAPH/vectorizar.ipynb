{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd82f8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Índice de schema reconstruído com 261 chunks.\n",
      "[INFO] Arquivo de vetores: schema_vetorizado\\schema_emb.npy\n",
      "[INFO] Arquivo de metadados: schema_vetorizado\\schema_chunks.json\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# CÉLULA 0 — VETORIZAR JSON DE SCHEMA (OFFLINE)\n",
    "# =========================\n",
    "# Use esta célula só quando mudar algum arquivo em schema/*.json.\n",
    "# Ela recria:\n",
    "#   schema_vetorizado/schema_emb.npy\n",
    "#   schema_vetorizado/schema_chunks.json\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import ollama\n",
    "\n",
    "# -------------------------\n",
    "# ARQUIVOS DE ENTRADA (SCHEMAS)\n",
    "# -------------------------\n",
    "SCHEMA_DIR = Path(\"schema\")\n",
    "\n",
    "ENTITY_TO_FILE = {\n",
    "    \"Agravo\": \"Agravo.json\",\n",
    "    \"AtividadeExec\": \"AtividadeExec.json\",\n",
    "    \"AtividadeResumo\": \"AtividadeResumo.json\",\n",
    "    \"Casos\": \"Casos.json\",\n",
    "    \"Dia\": \"Dia.json\",\n",
    "    \"Meteo\": \"Meteo.json\",\n",
    "    \"Municipio\": \"Municipio.json\",\n",
    "    \"Notificacao\": \"Notificacao.json\",\n",
    "    \"TipoAtividade\": \"TipoAtividade.json\",\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# ARQUIVOS DE SAÍDA (ÍNDICE VETORIAL)\n",
    "# -------------------------\n",
    "INDEX_DIR = Path(\"schema_vetorizado\")\n",
    "INDEX_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "EMB_PATH = INDEX_DIR / \"schema_emb.npy\"\n",
    "CHUNKS_PATH = INDEX_DIR / \"schema_chunks.json\"\n",
    "\n",
    "# Modelo de embedding\n",
    "EMBED_MODEL_NAME = os.environ.get(\"EMBED_MODEL_NAME\", \"bge-m3\")\n",
    "\n",
    "\n",
    "def _truncate(text, max_len):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = str(text).strip().replace(\"\\n\", \" \")\n",
    "    if len(text) <= max_len:\n",
    "        return text\n",
    "    return text[: max_len - 3] + \"...\"\n",
    "\n",
    "\n",
    "def _load_schema_json(filename):\n",
    "    path = SCHEMA_DIR / filename\n",
    "    if not path.exists():\n",
    "        print(f\"[WARN] Schema não encontrado: {path}\")\n",
    "        return None\n",
    "    try:\n",
    "        with path.open(encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if not isinstance(data, dict):\n",
    "            return None\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Não foi possível ler schema {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def _schema_to_chunks_for_embedding(schema, filename):\n",
    "    \"\"\"\n",
    "    Converte um schema JSON em vários 'chunks' semânticos:\n",
    "      - 1 chunk para a entidade\n",
    "      - 1 chunk por campo\n",
    "      - 1 chunk por relacionamento\n",
    "      - CASO ESPECIAL AtividadeExec: 1 chunk por tipo (1..16)\n",
    "        com campos_exclusivos e campos_comuns.\n",
    "    \"\"\"\n",
    "    no = schema.get(\"no\") or {}\n",
    "    label = no.get(\"label\") or filename.replace(\".json\", \"\")\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    # 1) Descrição da entidade\n",
    "    descr_ent = (no.get(\"descricao\") or schema.get(\"descricao_geral\") or \"\").strip()\n",
    "    descr_ent_short = _truncate(descr_ent, 256)\n",
    "    if descr_ent_short:\n",
    "        text = f\"Entidade {label}. {descr_ent_short}\"\n",
    "        chunks.append({\n",
    "            \"entity\": label,\n",
    "            \"filename\": filename,\n",
    "            \"kind\": \"entity\",\n",
    "            \"name\": label,\n",
    "            \"descr\": descr_ent_short,\n",
    "            \"text\": text,\n",
    "        })\n",
    "\n",
    "    # 2) Campos\n",
    "    props = {}\n",
    "\n",
    "    # comuns\n",
    "    if isinstance(no.get(\"propriedades\"), dict):\n",
    "        for name, meta in no[\"propriedades\"].items():\n",
    "            props[name] = meta or {}\n",
    "\n",
    "    # declarados dentro de tipos (AtividadeExec)\n",
    "    if isinstance(no.get(\"tipos\"), dict):\n",
    "        for _, tipo_info in no[\"tipos\"].items():\n",
    "            for name, meta in (tipo_info.get(\"propriedades\") or {}).items():\n",
    "                props.setdefault(name, meta or {})\n",
    "\n",
    "    for name, meta in props.items():\n",
    "        meta = meta or {}\n",
    "        tipo = (meta.get(\"tipo\") or \"\").strip()\n",
    "        descr = (meta.get(\"descricao\") or \"\").strip()\n",
    "        descr_short = _truncate(descr, 120)\n",
    "\n",
    "        text_parts = [f\"Campo {name} da entidade {label}.\"]\n",
    "        if tipo:\n",
    "            text_parts.append(f\"Tipo: {tipo}.\")\n",
    "        if descr_short:\n",
    "            text_parts.append(descr_short)\n",
    "        text = \" \".join(text_parts)\n",
    "\n",
    "        chunks.append({\n",
    "            \"entity\": label,\n",
    "            \"filename\": filename,\n",
    "            \"kind\": \"field\",\n",
    "            \"name\": name,\n",
    "            \"tipo\": tipo,\n",
    "            \"descr\": descr_short,\n",
    "            \"text\": text,\n",
    "        })\n",
    "\n",
    "    # 3) Relacionamentos\n",
    "    rels = schema.get(\"relacoes\") or []\n",
    "    for r in rels:\n",
    "        tipo_rel = (r.get(\"tipo\") or \"\").strip()\n",
    "        de = (r.get(\"de\") or \"\").strip()\n",
    "        para = (r.get(\"para\") or \"\").strip()\n",
    "        if not (tipo_rel and de and para):\n",
    "            continue\n",
    "\n",
    "        descr = (r.get(\"descricao\") or \"\").strip()\n",
    "        descr_short = _truncate(descr, 120)\n",
    "\n",
    "        text = (\n",
    "            f\"Relação {tipo_rel} entre {de} e {para} envolvendo a entidade {label}. \"\n",
    "            f\"{descr_short}\"\n",
    "        )\n",
    "\n",
    "        chunks.append({\n",
    "            \"entity\": label,\n",
    "            \"filename\": filename,\n",
    "            \"kind\": \"rel\",\n",
    "            \"tipo_rel\": tipo_rel,\n",
    "            \"de\": de,\n",
    "            \"para\": para,\n",
    "            \"descr\": descr_short,\n",
    "            \"text\": text,\n",
    "        })\n",
    "\n",
    "    # 4) CASO ESPECIAL: TIPOS AtividadeExec (1..16)\n",
    "    if label == \"AtividadeExec\":\n",
    "        tipos = no.get(\"tipos\") or {}\n",
    "        if isinstance(tipos, dict) and tipos:\n",
    "            campos_por_tipo = {}\n",
    "            for tipo_cod, info in tipos.items():\n",
    "                props_tipo = (info.get(\"propriedades\") or {})\n",
    "                campos_por_tipo[str(tipo_cod)] = set(props_tipo.keys())\n",
    "\n",
    "            all_campos = set().union(*campos_por_tipo.values())\n",
    "            campos_comuns = set(all_campos)\n",
    "            for s in campos_por_tipo.values():\n",
    "                campos_comuns &= s\n",
    "            campos_comuns = sorted(campos_comuns)\n",
    "\n",
    "            for tipo_cod, info in tipos.items():\n",
    "                desc = (info.get(\"descricao\") or \"\").strip()\n",
    "                desc_short = _truncate(desc, 256)\n",
    "                exclusivos = sorted(\n",
    "                    list(campos_por_tipo[str(tipo_cod)] - set(campos_comuns))\n",
    "                )\n",
    "\n",
    "                texto_partes = [f\"Tipo de atividade {tipo_cod} da entidade {label}.\"]\n",
    "                if desc_short:\n",
    "                    texto_partes.append(desc_short)\n",
    "                if exclusivos:\n",
    "                    texto_partes.append(\n",
    "                        \"Campos exclusivos deste tipo: \" + \", \".join(exclusivos) + \".\"\n",
    "                    )\n",
    "                if campos_comuns:\n",
    "                    texto_partes.append(\n",
    "                        \"Campos comuns a todos os tipos: \" + \", \".join(campos_comuns) + \".\"\n",
    "                    )\n",
    "                text = \" \".join(texto_partes)\n",
    "\n",
    "                chunks.append({\n",
    "                    \"entity\": label,\n",
    "                    \"filename\": filename,\n",
    "                    \"kind\": \"tipo\",\n",
    "                    \"tipo_codigo\": str(tipo_cod),\n",
    "                    \"name\": f\"tipo {tipo_cod}\",\n",
    "                    \"descr\": desc_short,\n",
    "                    \"campos_exclusivos\": exclusivos,\n",
    "                    \"campos_comuns\": campos_comuns,\n",
    "                    \"text\": text,\n",
    "                })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def _embed_text(text):\n",
    "    resp = ollama.embeddings(\n",
    "        model=EMBED_MODEL_NAME,\n",
    "        prompt=text,\n",
    "    )\n",
    "    return resp[\"embedding\"]\n",
    "\n",
    "\n",
    "def rebuild_schema_index():\n",
    "    \"\"\"\n",
    "    Recria COMPLETAMENTE o índice vetorial a partir de schema/*.json\n",
    "    e salva em schema_vetorizado/.\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "\n",
    "    for ent, fname in ENTITY_TO_FILE.items():\n",
    "        schema = _load_schema_json(fname)\n",
    "        if not schema:\n",
    "            continue\n",
    "        chunks = _schema_to_chunks_for_embedding(schema, fname)\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    if not all_chunks:\n",
    "        print(\"[WARN] Nenhum chunk de schema encontrado para vetorização.\")\n",
    "        return\n",
    "\n",
    "    embeddings = []\n",
    "    for ch in all_chunks:\n",
    "        emb = _embed_text(ch[\"text\"])\n",
    "        embeddings.append(emb)\n",
    "\n",
    "    emb_matrix = np.array(embeddings, dtype=\"float32\")\n",
    "\n",
    "    np.save(EMB_PATH, emb_matrix)\n",
    "    with CHUNKS_PATH.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_chunks, f, ensure_ascii=False)\n",
    "\n",
    "    print(f\"[INFO] Índice de schema reconstruído com {emb_matrix.shape[0]} chunks.\")\n",
    "    print(f\"[INFO] Arquivo de vetores: {EMB_PATH}\")\n",
    "    print(f\"[INFO] Arquivo de metadados: {CHUNKS_PATH}\")\n",
    "\n",
    "\n",
    "rebuild_schema_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bb258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
