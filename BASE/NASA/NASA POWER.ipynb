{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e83767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time, random, threading\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Set\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from shapely.geometry import shape\n",
    "\n",
    "GEOJSON_PATH   = r'geojs-35-mun.json'      \n",
    "OUTPUT_DIR     = r'MINERACAO NASA'      \n",
    "DATA_DIR       = os.path.join(OUTPUT_DIR, 'data')     \n",
    "CHECK_DIR      = os.path.join(OUTPUT_DIR, 'checkpoints')   \n",
    "\n",
    "COMMUNITY      = 'AG'                       \n",
    "REQUEST_TIMEOUT = 90                      \n",
    "RETRIES         = 3                    \n",
    "BACKOFF_BASE    = 2.0                      \n",
    "ROUND_TO_GRID   = True                     \n",
    "\n",
    "MIN_SECS_BETWEEN_CALLS = 1.0   \n",
    "\n",
    "\n",
    "START_DATE = '20200101'  \n",
    "END_DATE   = '20241231'   \n",
    "\n",
    "MET_PARAMS: List[str] = [\n",
    "    'T2M_MAX','T2M_MIN','T2M',\n",
    "    'RH2M','QV2M',\n",
    "    'PS',\n",
    "    'WS2M','WD2M',\n",
    "    'PRECTOT',\n",
    "    'T2MDEW','T2MWET','T2M_RANGE',\n",
    "    'ALLSKY_SFC_SW_DWN','ALLSKY_SFC_LW_DWN','CLRSKY_SFC_SW_DWN',\n",
    "    'HDD0','CDD0','HDD10','CDD10',\n",
    "    'PRECTOTCORR',\n",
    "    'TS',\n",
    "    'PW',\n",
    "    'ALLSKY_SFC_PAR_TOT',\n",
    "    'WS2M_MAX','WS2M_MIN','WS2M_RANGE'\n",
    "]\n",
    "\n",
    "\n",
    "ALIASES = {\n",
    "    \"PRECIP_TOT\": [\"PRECTOTCORR\", \"PRECTOT\"], \n",
    "}\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, min_interval_sec: float):\n",
    "        self.min_interval = float(min_interval_sec)\n",
    "        self._lock = threading.Lock()\n",
    "        self._last = 0.0\n",
    "\n",
    "    def wait(self):\n",
    "        with self._lock:\n",
    "            now = time.time()\n",
    "            gap = now - self._last\n",
    "            if gap < self.min_interval:\n",
    "                time.sleep(self.min_interval - gap)\n",
    "            self._last = time.time()\n",
    "\n",
    "_rate = RateLimiter(MIN_SECS_BETWEEN_CALLS)\n",
    "\n",
    "def jitter_sleep(base: float, attempt: int):\n",
    "    delay = (base ** attempt) + random.random()\n",
    "    time.sleep(min(delay, 30.0))\n",
    "\n",
    "def round_to_half_degree(v: float) -> float:\n",
    "    return round(v * 2) / 2.0\n",
    "\n",
    "def generate_date_ranges_fixed() -> List[Tuple[str, str]]:\n",
    "    s = pd.to_datetime(START_DATE, format='%Y%m%d')\n",
    "    e = pd.to_datetime(END_DATE,   format='%Y%m%d')\n",
    "    ranges, cur = [], s\n",
    "    while cur <= e:\n",
    "        ne = min(cur + pd.Timedelta(days=365 - 1), e)\n",
    "        ranges.append((cur.strftime('%Y%m%d'), ne.strftime('%Y%m%d')))\n",
    "        cur = ne + pd.Timedelta(days=1)\n",
    "    return ranges\n",
    "\n",
    "def normalize_date_str(dt: str) -> str:\n",
    "    if isinstance(dt, str) and len(dt) == 8 and dt.isdigit():\n",
    "        try:\n",
    "            return pd.to_datetime(dt, format='%Y%m%d').strftime('%Y-%m-%d')\n",
    "        except Exception:\n",
    "            return dt\n",
    "    return dt\n",
    "\n",
    "def load_municipios_centroides(geojson_path: str) -> List[Dict]:\n",
    "    with open(geojson_path, 'r', encoding='utf-8') as f:\n",
    "        geo = json.load(f)\n",
    "    out = []\n",
    "    for feat in geo.get('features', []):\n",
    "        props = feat.get('properties', {})\n",
    "        geom  = feat.get('geometry')\n",
    "        if not geom:\n",
    "            continue\n",
    "        try:\n",
    "            poly = shape(geom)\n",
    "            pt = poly.representative_point()  \n",
    "            lon, lat = pt.x, pt.y\n",
    "            out.append({\n",
    "                'id': props.get('id'),\n",
    "                'name': props.get('name'),\n",
    "                'latitude': lat,\n",
    "                'longitude': lon\n",
    "            })\n",
    "        except Exception:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "def safe_name(name: str) -> str:\n",
    "    return str(name).strip().replace(' ', '_').replace('/', '_').replace('\\\\', '_')\n",
    "\n",
    "def city_paths(name: str) -> Tuple[str, str]:\n",
    "    base = safe_name(name)\n",
    "    return os.path.join(DATA_DIR, f\"{base}.json\"), os.path.join(CHECK_DIR, f\"{base}.json\")\n",
    "\n",
    "def load_city_checkpoint(path: str) -> int:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                obj = json.load(f)\n",
    "                return int(obj.get('last_window', -1))\n",
    "        except Exception:\n",
    "            return -1\n",
    "    return -1\n",
    "\n",
    "def save_city_checkpoint(path: str, last_w: int):\n",
    "    try:\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump({'last_window': last_w, 'updated_at': datetime.utcnow().isoformat()+'Z'}, f, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def load_city_data(path: str) -> Dict[str, Dict[str, float]]:\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                arr = json.load(f)\n",
    "                out = {}\n",
    "                for rec in arr:\n",
    "                    d = rec.get('date')\n",
    "                    if not d: continue\n",
    "                    out[d] = {k: v for k, v in rec.items() if k != 'date'}\n",
    "                return out\n",
    "        except Exception:\n",
    "            return {}\n",
    "    return {}\n",
    "\n",
    "def save_city_data(path: str, date_map: Dict[str, Dict[str, float]]):\n",
    "    items = sorted(date_map.items(), key=lambda kv: kv[0])\n",
    "    arr = []\n",
    "    for d, vals in items:\n",
    "        rec = {'date': d}\n",
    "        rec.update(vals)\n",
    "        arr.append(rec)\n",
    "    try:\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(arr, f, ensure_ascii=False, indent=2)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def _request_power(lat: float, lon: float, param: str, start: str, end: str, community: str):\n",
    "    base_url = 'https://power.larc.nasa.gov/api/temporal/daily/point'\n",
    "    q = {\n",
    "        'start': start, 'end': end,\n",
    "        'latitude': lat, 'longitude': lon,\n",
    "        'parameters': param,\n",
    "        'community': community,\n",
    "        'format': 'JSON'\n",
    "    }\n",
    "\n",
    "    sess = requests.Session()\n",
    "    for attempt in range(1, RETRIES + 1):\n",
    "        _rate.wait()  \n",
    "\n",
    "        try:\n",
    "            r = sess.get(base_url, params=q, timeout=REQUEST_TIMEOUT)\n",
    "            try:\n",
    "                payload = r.json()\n",
    "            except Exception:\n",
    "                payload = r.text\n",
    "\n",
    "            if r.status_code == 422 and ROUND_TO_GRID and attempt == 1:\n",
    "                lat_r, lon_r = round_to_half_degree(lat), round_to_half_degree(lon)\n",
    "                q2 = dict(q)\n",
    "                q2['latitude'] = lat_r\n",
    "                q2['longitude'] = lon_r\n",
    "\n",
    "                _rate.wait()\n",
    "                r2 = sess.get(base_url, params=q2, timeout=REQUEST_TIMEOUT)\n",
    "                try:\n",
    "                    payload2 = r2.json()\n",
    "                except Exception:\n",
    "                    payload2 = r2.text\n",
    "\n",
    "                if r2.status_code == 200 and isinstance(payload2, dict):\n",
    "                    return 200, payload2\n",
    "\n",
    "\n",
    "            if r.status_code == 200 and isinstance(payload, dict):\n",
    "                return 200, payload\n",
    "\n",
    "            if attempt < RETRIES:\n",
    "                jitter_sleep(BACKOFF_BASE, attempt)\n",
    "                continue\n",
    "            else:\n",
    "                return r.status_code, payload\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt < RETRIES:\n",
    "                jitter_sleep(BACKOFF_BASE, attempt)\n",
    "                continue\n",
    "            else:\n",
    "                return -1, str(e)\n",
    "\n",
    "    return -1, \"erro_desconhecido\"\n",
    "\n",
    "def fetch_param_series(lat: float, lon: float, param: str, start: str, end: str, community: str) -> Dict[str, float]:\n",
    "    code, payload = _request_power(lat, lon, param, start, end, community)\n",
    "    if code == 200 and isinstance(payload, dict):\n",
    "        return payload.get('properties', {}).get('parameter', {}).get(param, {}) or {}\n",
    "    return {}\n",
    "\n",
    "def merge_window_param(date_map: Dict[str, Dict[str, float]], param: str, series: Dict[str, float]):\n",
    "    for dt, val in series.items():\n",
    "        d = normalize_date_str(dt)\n",
    "        tgt = date_map.setdefault(d, {})\n",
    "        tgt[param] = val\n",
    "\n",
    "def process_city_sequential(m: Dict, date_windows: List[Tuple[str, str]]) -> Tuple[str, int, Set[str]]:\n",
    "    mid, name, lat, lon = m['id'], m['name'], m['latitude'], m['longitude']\n",
    "    data_path, ck_path = city_paths(name)\n",
    "\n",
    "    last_w = load_city_checkpoint(ck_path)\n",
    "    date_map = load_city_data(data_path)\n",
    "\n",
    "    nwin = len(date_windows)\n",
    "    print(f\"[{name}] retomando da janela {last_w+1}/{nwin}\")\n",
    "\n",
    "    invalid_params: Set[str] = set()\n",
    "\n",
    "    for wi in range(last_w + 1, nwin):\n",
    "        st, ed = date_windows[wi]\n",
    "        print(f\"  [{name}] Janela {wi+1}/{nwin}: {st}..{ed}\")\n",
    "\n",
    "        returned_params: Set[str] = set()\n",
    "\n",
    "        for p in MET_PARAMS:\n",
    "            series = fetch_param_series(lat, lon, p, st, ed, COMMUNITY)\n",
    "            if series:\n",
    "                merge_window_param(date_map, p, series)\n",
    "                returned_params.add(p)\n",
    "            else:\n",
    "                invalid_params.add(p)\n",
    "\n",
    "        covered = set(returned_params)\n",
    "        for alias, variants in ALIASES.items():\n",
    "            if any(v in returned_params for v in variants):\n",
    "                covered.add(alias)\n",
    "        desired_for_report = (set(MET_PARAMS) - {\"PRECTOT\"}) | set(ALIASES.keys())\n",
    "        missing_now = sorted(list(desired_for_report - covered))\n",
    "\n",
    "        ok_n = len(returned_params)\n",
    "        print(f\"    OK {ok_n} params | faltando agora: {missing_now or 'nenhum'}\")\n",
    "\n",
    "        for d, vals in date_map.items():\n",
    "            if 'PRECTOT' in vals and vals['PRECTOT'] is None:\n",
    "                vals['PRECTOT'] = 0\n",
    "            if vals.get('PRECTOTCORR') is not None:\n",
    "                vals['PRECIP'] = vals['PRECTOTCORR']\n",
    "            elif 'PRECTOT' in vals:\n",
    "                vals['PRECIP'] = vals['PRECTOT']\n",
    "            if 'T2M' not in vals and vals.get('T2M_MAX') is not None and vals.get('T2M_MIN') is not None:\n",
    "                vals['T2M_MEAN_CALC'] = (vals['T2M_MAX'] + vals['T2M_MIN']) / 2.0\n",
    "\n",
    "        save_city_data(data_path, date_map)\n",
    "        save_city_checkpoint(ck_path, wi)\n",
    "\n",
    "    total_rows = len(date_map)\n",
    "    print(f\"[{name}] concluído — {total_rows} linhas; possivelmente inválidos: {sorted(list(invalid_params)) or 'nenhum'}\")\n",
    "    return name, total_rows, invalid_params\n",
    "\n",
    "def main():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    os.makedirs(DATA_DIR, exist_ok=True)\n",
    "    os.makedirs(CHECK_DIR, exist_ok=True)\n",
    "\n",
    "    assert START_DATE == '20200101' and END_DATE == '20241231', \"Período deve ser 2020-01-01 .. 2024-12-31\"\n",
    "    date_windows = generate_date_ranges_fixed()\n",
    "\n",
    "    municipios = load_municipios_centroides(GEOJSON_PATH)\n",
    "    print(f\"Total de municípios: {len(municipios)}\")\n",
    "    print(f\"Janelas (365d): {len(date_windows)} — cobrindo {START_DATE}..{END_DATE}\")\n",
    "    print(f\"Parâmetros (um a um): {len(MET_PARAMS)}\")\n",
    "\n",
    "    all_invalid: Set[str] = set()\n",
    "    results = []\n",
    "\n",
    "    for m in municipios:\n",
    "        try:\n",
    "            name, nrows, invalid_local = process_city_sequential(m, date_windows)\n",
    "            results.append((name, nrows))\n",
    "            all_invalid |= invalid_local\n",
    "        except Exception as e:\n",
    "            print(f\"[ERRO] {m.get('name')}: {e}\")\n",
    "\n",
    "    if all_invalid:\n",
    "        print(\"\\n Parâmetros que falharam para pelo menos um município/janela:\")\n",
    "        print(sorted(list(all_invalid)))\n",
    "    else:\n",
    "        print(\"\\n Nenhum parâmetro falhou em toda a execução.\")\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nTop-5 por linhas gravadas:\")\n",
    "    for nm, n in results[:5]:\n",
    "        print(f\"  {nm}: {n} linhas\")\n",
    "\n",
    "    print(\"\\nProcessamento finalizado.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
