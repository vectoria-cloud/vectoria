{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f029f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, glob, os\n",
    "import time\n",
    "import subprocess\n",
    "from neo4j import GraphDatabase\n",
    "from neo4j.exceptions import ServiceUnavailable, SessionExpired, TransientError, ClientError\n",
    "\n",
    "# ========= CONFIG =========\n",
    "FOLDER_JSONS = r\"TRATADOS\\\\*.json\"\n",
    "NEO4J_URI  = \"\"\n",
    "NEO4J_USER = \"\"\n",
    "NEO4J_PASS = \"\"\n",
    "NEO4J_DB   = \"\"\n",
    "SPATIAL_LAYER = \"municipios_wkt\"\n",
    "PROGRESS_FILE = \"\"\n",
    "\n",
    "\n",
    "SAFE_CHUNK_SIZE = 2000       \n",
    "MAX_FAST_RECORDS = 120_000    \n",
    "\n",
    "\n",
    "class Neo4jDatabaseManager:\n",
    "    def __init__(self, uri, user, password, database):\n",
    "        self.uri = uri\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.database = database\n",
    "        self.driver = None\n",
    "    \n",
    "    def ensure_database_exists(self):\n",
    "        \n",
    "        try:\n",
    "            self.driver = GraphDatabase.driver(\n",
    "                self.uri, \n",
    "                auth=(self.user, self.password),\n",
    "                max_connection_lifetime=3600\n",
    "            )\n",
    "            \n",
    "            with self.driver.session(database=\"system\") as session:\n",
    "                result = session.run(\"SHOW DATABASES\")\n",
    "                databases = [record[\"name\"] for record in result]\n",
    "                \n",
    "                if self.database in databases:\n",
    "                    \n",
    "                    status_result = session.run(\n",
    "                        \"SHOW DATABASE $db YIELD name, currentStatus\",\n",
    "                        db=self.database\n",
    "                    )\n",
    "                    status_info = status_result.single()\n",
    "                    if status_info:\n",
    "                        status = status_info[\"currentStatus\"]\n",
    "\n",
    "                        \n",
    "                        if status == \"online\":\n",
    "                            return True\n",
    "                        else:\n",
    "                            return self._start_database()\n",
    "                    else:\n",
    "                        return self._create_database()\n",
    "                else:\n",
    "                    return self._create_database()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            return self._fallback_creation()\n",
    "    \n",
    "    def _create_database(self):\n",
    "        try:\n",
    "            with self.driver.session(database=\"system\") as session:\n",
    "                session.run(f\"CREATE DATABASE `{self.database}`\")\n",
    "                return self._wait_for_database_online()\n",
    "        except Exception as e:\n",
    "            return self._fallback_creation()\n",
    "    \n",
    "    def _start_database(self):\n",
    "        try:\n",
    "            with self.driver.session(database=\"system\") as session:\n",
    "                session.run(f\"START DATABASE `{self.database}`\")\n",
    "                return self._wait_for_database_online()\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def _wait_for_database_online(self, max_wait=60):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while time.time() - start_time < max_wait:\n",
    "            try:\n",
    "                with self.driver.session(database=\"system\") as session:\n",
    "                    result = session.run(\n",
    "                        \"SHOW DATABASE $db YIELD name, currentStatus\",\n",
    "                        db=self.database\n",
    "                    )\n",
    "                    status_info = result.single()\n",
    "                    \n",
    "                    if status_info and status_info[\"currentStatus\"] == \"online\":\n",
    "                        return True\n",
    "                    else:\n",
    "                        status = status_info[\"currentStatus\"] if status_info else \"unknown\"\n",
    "                        time.sleep(5)\n",
    "            except Exception as e:\n",
    "                time.sleep(5)\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _fallback_creation(self):\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [\n",
    "                    \"neo4j-admin\", \"database\", \"create\", self.database,\n",
    "                    \"--verbose\"\n",
    "                ],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=30\n",
    "            )\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                subprocess.run([\"neo4j\", \"restart\"], timeout=60)\n",
    "                time.sleep(10)\n",
    "                return self._wait_for_database_online()\n",
    "            else:\n",
    "                return False\n",
    "                \n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def test_connection(self):\n",
    "        try:\n",
    "            with self.driver.session(database=self.database) as session:\n",
    "                result = session.run(\"RETURN 'ConexÃ£o OK' as status\")\n",
    "                return result.single()[\"status\"] == \"ConexÃ£o OK\"\n",
    "        except Exception as e:\n",
    "            return False\n",
    "    \n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "\n",
    "\n",
    "class Neo4jConnectionManager:\n",
    "    def __init__(self, uri, user, password, database):\n",
    "        self.uri = uri\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.database = database\n",
    "        self.driver = None\n",
    "        self._connect()\n",
    "    \n",
    "    def _connect(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            self.uri, \n",
    "            auth=(self.user, self.password),\n",
    "            max_connection_lifetime=3600,\n",
    "            max_connection_pool_size=10,\n",
    "            connection_acquisition_timeout=300,\n",
    "            connection_timeout=300,\n",
    "        )\n",
    "        with self.driver.session(database=self.database) as session:\n",
    "            session.run(\"RETURN 1\")\n",
    "    \n",
    "    def get_session(self):\n",
    "        try:\n",
    "            return self.driver.session(database=self.database)\n",
    "        except (ServiceUnavailable, SessionExpired, TransientError):\n",
    "            self._connect()\n",
    "            return self.driver.session(database=self.database)\n",
    "    \n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "\n",
    "CYPHER_CONSTRAINTS = [\n",
    "    \"\"\"CREATE CONSTRAINT municipio_ibge IF NOT EXISTS\n",
    "       FOR (m:Municipio) REQUIRE m.ibge_id IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT dia_key IF NOT EXISTS\n",
    "       FOR (d:Dia) REQUIRE d.date IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT meteo_key IF NOT EXISTS\n",
    "       FOR (mm:Meteo) REQUIRE (mm.municipio_id, mm.date) IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT casos_key IF NOT EXISTS\n",
    "       FOR (c:Casos) REQUIRE (c.municipio_id, c.date, c.agravo) IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT notif_key IF NOT EXISTS\n",
    "       FOR (n:Notificacao) REQUIRE n.notif_id IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT tipo_ativ_key IF NOT EXISTS\n",
    "       FOR (t:TipoAtividade) REQUIRE t.codigo IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT ativ_exec_key IF NOT EXISTS\n",
    "       FOR (a:AtividadeExec) REQUIRE a.exec_id IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT agravo_codigo IF NOT EXISTS\n",
    "       FOR (g:Agravo) REQUIRE g.codigo IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE CONSTRAINT ativ_resumo_key IF NOT EXISTS\n",
    "       FOR (ar:AtividadeResumo) REQUIRE (ar.municipio_id, ar.date, ar.tipo) IS UNIQUE\"\"\",\n",
    "    \"\"\"CREATE INDEX ativ_exec_municipio_date_sisaweb_tipo IF NOT EXISTS\n",
    "       FOR (a:AtividadeExec)\n",
    "       ON (a.municipio_id, a.date, a.sisaweb_tipo)\"\"\"\n",
    "]\n",
    "\n",
    "CYPHER_UPSERT_MUNICIPIO = \"\"\"\n",
    "MERGE (m:Municipio {ibge_id: $ibge_id})\n",
    "  ON CREATE SET\n",
    "      m.nome        = $nome,\n",
    "      m.sisaweb_id  = $sisaweb_id,\n",
    "      m.geojson_str = $geojson_str,\n",
    "      m.wkt         = $wkt\n",
    "  ON MATCH SET\n",
    "      m.nome        = coalesce(m.nome, $nome),\n",
    "      m.sisaweb_id  = coalesce(m.sisaweb_id, $sisaweb_id),\n",
    "      m.geojson_str = coalesce(m.geojson_str, $geojson_str),\n",
    "      m.wkt         = coalesce(m.wkt, $wkt)\n",
    "WITH m, $lon AS lon, $lat AS lat\n",
    "FOREACH (_ IN CASE WHEN lon IS NULL OR lat IS NULL THEN [] ELSE [1] END |\n",
    "  SET m.location = point({longitude: lon, latitude: lat})\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_BULK_DIAS = \"\"\"\n",
    "UNWIND $dias AS row\n",
    "MERGE (d:Dia {date: date(row.dt)})\n",
    "WITH d, row\n",
    "MATCH (m:Municipio {ibge_id: row.ibge_id})\n",
    "MERGE (m)-[:TEM_DADO_NO_DIA]->(d)\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_BULK_METEO = \"\"\"\n",
    "UNWIND $met AS row\n",
    "MATCH (d:Dia {date: date(row.dt)})\n",
    "MATCH (m:Municipio {ibge_id: row.ibge_id})\n",
    "MERGE (mm:Meteo {municipio_id: row.ibge_id, date: date(row.dt)})\n",
    "SET mm += row.meteo_map\n",
    "MERGE (m)-[:TEM_METEOROLOGIA]->(mm)\n",
    "MERGE (d)-[:TEM_METEOROLOGIA]->(mm)\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_BULK_ATIV = \"\"\"\n",
    "UNWIND $ativ AS at\n",
    "MATCH (m:Municipio {ibge_id: at.municipio_id})\n",
    "MATCH (d:Dia {date: date(at.dt)})\n",
    "MERGE (a:AtividadeExec {exec_id: at.exec_id})\n",
    "SET a.municipio_id = at.municipio_id,\n",
    "    a.date         = date(at.dt),\n",
    "    a.sisaweb_tipo = at.tipo,\n",
    "    a.atividade    = at.atividade\n",
    "SET a += at.props\n",
    "MERGE (m)-[:EXECUTOU_ATIVIDADE]->(a)\n",
    "MERGE (a)-[:NO_DIA]->(d)\n",
    "MERGE (t:TipoAtividade {codigo: at.tipo})\n",
    "MERGE (a)-[:E_DO_TIPO]->(t)\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_BULK_ATIV_RESUMO = \"\"\"\n",
    "UNWIND $resumos AS r\n",
    "MATCH (m:Municipio {ibge_id: r.municipio_id})\n",
    "MATCH (d:Dia {date: date(r.dt)})\n",
    "MERGE (t:TipoAtividade {codigo: r.tipo})\n",
    "MERGE (ar:AtividadeResumo {\n",
    "  municipio_id: r.municipio_id,\n",
    "  date: date(r.dt),\n",
    "  tipo: r.tipo\n",
    "})\n",
    "SET ar.qtd_execucoes = r.qtd_execucoes\n",
    "MERGE (m)-[:TEM_ATIVIDADE_RESUMO]->(ar)\n",
    "MERGE (d)-[:TEM_ATIVIDADE_RESUMO]->(ar)\n",
    "MERGE (ar)-[:E_DO_TIPO]->(t)\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_LINK_ATIV_RESUMO = \"\"\"\n",
    "UNWIND $resumos AS r\n",
    "MATCH (ar:AtividadeResumo {\n",
    "  municipio_id: r.municipio_id,\n",
    "  date: date(r.dt),\n",
    "  tipo: r.tipo\n",
    "})\n",
    "MATCH (a:AtividadeExec {\n",
    "  municipio_id: r.municipio_id,\n",
    "  date: date(r.dt),\n",
    "  sisaweb_tipo: r.tipo\n",
    "})\n",
    "MERGE (a)-[:CONTA_PARA]->(ar)\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_BULK_CASOS = \"\"\"\n",
    "UNWIND $casos AS cs\n",
    "MATCH (d:Dia {date: date(cs.dt)})\n",
    "MATCH (m:Municipio {ibge_id: cs.municipio_id})\n",
    "MERGE (c:Casos {\n",
    "  municipio_id: cs.municipio_id,\n",
    "  date: date(cs.dt),\n",
    "  agravo: cs.agravo\n",
    "})\n",
    "SET c += cs.props\n",
    "MERGE (m)-[:TEM_CASOS]->(c)\n",
    "MERGE (d)-[:TEM_CASOS]->(c)\n",
    "MERGE (ag:Agravo {codigo: cs.agravo})\n",
    "MERGE (c)-[:E_DO_AGRAVO]->(ag)\n",
    "\"\"\"\n",
    "\n",
    "CYPHER_BULK_NOTIFS = \"\"\"\n",
    "UNWIND $notifs AS nf\n",
    "MATCH (d:Dia {date: date(nf.dt)})\n",
    "MATCH (m:Municipio {ibge_id: nf.municipio_id})\n",
    "MERGE (n:Notificacao {notif_id: nf.notif_id})\n",
    "SET n.municipio_id = nf.municipio_id,\n",
    "    n.agravo       = nf.agravo,\n",
    "    n.dt_notific   = CASE \n",
    "        WHEN nf.dt_notific IS NULL OR nf.dt_notific = \"\" OR nf.dt_notific = \"        \" THEN null \n",
    "        ELSE date(nf.dt_notific) \n",
    "    END,\n",
    "    n.id_unidade   = nf.id_unidade,\n",
    "    n.dt_nasc      = CASE \n",
    "        WHEN nf.dt_nasc IS NULL OR nf.dt_nasc = \"\" OR nf.dt_nasc = \"        \" THEN null \n",
    "        ELSE date(nf.dt_nasc) \n",
    "    END,\n",
    "    n.cs_sexo      = nf.cs_sexo,\n",
    "    n.cs_gestant   = nf.cs_gestant,\n",
    "    n.cs_raca      = nf.cs_raca,\n",
    "    n.cs_escol_n   = nf.cs_escol_n,\n",
    "    n.dt_obito     = CASE\n",
    "        WHEN nf.dt_obito IS NULL OR nf.dt_obito = \"\" OR nf.dt_obito = \"        \" THEN null\n",
    "        ELSE date(nf.dt_obito)\n",
    "    END\n",
    "SET n += nf.props_adicionais\n",
    "MERGE (m)-[:TEM_NOTIFICACAO]->(n)\n",
    "MERGE (d)-[:TEM_NOTIFICACAO]->(n)\n",
    "MERGE (ag:Agravo {codigo: nf.agravo})\n",
    "MERGE (n)-[:E_DO_AGRAVO]->(ag)\n",
    "WITH n, nf\n",
    "MATCH (c:Casos {\n",
    "  municipio_id: nf.municipio_id,\n",
    "  date: date(nf.dt),\n",
    "  agravo: nf.agravo\n",
    "})\n",
    "MERGE (n)-[:CONTA_PARA]->(c)\n",
    "\"\"\"\n",
    "\n",
    "def close_ring_if_needed(r):\n",
    "    if not r:\n",
    "        return r\n",
    "    if (r[0][0], r[0][1]) != (r[-1][0], r[-1][1]):\n",
    "        r = r + [r[0]]\n",
    "    return r\n",
    "\n",
    "def polygon_to_wkt(coords):\n",
    "    rings = []\n",
    "    for ring in coords:\n",
    "        ring = close_ring_if_needed(ring)\n",
    "        rings.append(\"(\" + \", \".join(f\"{float(x)} {float(y)}\" for x, y in ring) + \")\")\n",
    "    return f\"POLYGON({','.join(rings)})\"\n",
    "\n",
    "def multipolygon_to_wkt(coords):\n",
    "    polys = []\n",
    "    for poly in coords:\n",
    "        rings = []\n",
    "        for ring in poly:\n",
    "            ring = close_ring_if_needed(ring)\n",
    "            rings.append(\"(\" + \", \".join(f\"{float(x)} {float(y)}\" for x, y in ring) + \")\")\n",
    "        polys.append(\"(\" + \",\".join(rings) + \")\")\n",
    "    return f\"MULTIPOLYGON({','.join(polys)})\"\n",
    "\n",
    "def geojson_to_wkt(geo):\n",
    "    if not isinstance(geo, dict):\n",
    "        return None\n",
    "    t = geo.get(\"type\")\n",
    "    c = geo.get(\"coordinates\")\n",
    "    if t == \"Polygon\" and c:\n",
    "        return polygon_to_wkt(c)\n",
    "    if t == \"MultiPolygon\" and c:\n",
    "        return multipolygon_to_wkt(c)\n",
    "    return None\n",
    "\n",
    "def centroid_from_geojson(geo):\n",
    "    if not isinstance(geo, dict):\n",
    "        return None\n",
    "    t = geo.get(\"type\")\n",
    "    c = geo.get(\"coordinates\")\n",
    "    ring = c[0] if t == \"Polygon\" and c else (c[0][0] if t == \"MultiPolygon\" and c else None)\n",
    "    if not ring:\n",
    "        return None\n",
    "    xs = ys = n = 0.0\n",
    "    for p in ring:\n",
    "        if isinstance(p, list) and len(p) >= 2:\n",
    "            xs += float(p[0])\n",
    "            ys += float(p[1])\n",
    "            n += 1\n",
    "    return (xs / n, ys / n) if n else None\n",
    "\n",
    "INT64_MIN = -(1 << 63)\n",
    "INT64_MAX = (1 << 63) - 1\n",
    "\n",
    "def _safe_number(v):\n",
    "    if isinstance(v, bool):\n",
    "        return v\n",
    "    if isinstance(v, int):\n",
    "        return v if INT64_MIN <= v <= INT64_MAX else str(v)\n",
    "    if isinstance(v, float):\n",
    "        import math\n",
    "        return v if math.isfinite(v) else str(v)\n",
    "    return v\n",
    "\n",
    "def sanitize_value(v):\n",
    "    if v is None or isinstance(v, (str, bool)):\n",
    "        return v\n",
    "    if isinstance(v, (int, float)):\n",
    "        return _safe_number(v)\n",
    "    if isinstance(v, list):\n",
    "        if any(isinstance(i, (list, dict)) for i in v):\n",
    "            return json.dumps(v, ensure_ascii=False)\n",
    "        out = []\n",
    "        for i in v:\n",
    "            if isinstance(i, (str, bool)) or i is None:\n",
    "                out.append(i)\n",
    "            elif isinstance(i, (int, float)):\n",
    "                out.append(_safe_number(i))\n",
    "            else:\n",
    "                return json.dumps(v, ensure_ascii=False)\n",
    "        return out\n",
    "    if isinstance(v, dict):\n",
    "        return json.dumps(v, ensure_ascii=False)\n",
    "    return json.dumps(v, ensure_ascii=False)\n",
    "\n",
    "def is_valid_date(date_str):\n",
    "    if not date_str or not isinstance(date_str, str):\n",
    "        return False\n",
    "    date_str = date_str.strip()\n",
    "    if date_str in [\"\", \"        \"]:\n",
    "        return False\n",
    "    if len(date_str) == 10 and date_str[4] == \"-\" and date_str[7] == \"-\":\n",
    "        try:\n",
    "            year = int(date_str[:4])\n",
    "            month = int(date_str[5:7])\n",
    "            day = int(date_str[8:10])\n",
    "            if 1900 <= year <= 2100 and 1 <= month <= 12 and 1 <= day <= 31:\n",
    "                return True\n",
    "        except (ValueError, IndexError):\n",
    "            pass\n",
    "    return False\n",
    "\n",
    "def normalize_meteo_dict(m):\n",
    "    if not isinstance(m, dict):\n",
    "        return {}\n",
    "    return {k: sanitize_value(v) for k, v in m.items() if v is not None}\n",
    "\n",
    "def normalize_casos(doc_ibge, raw):\n",
    "    casos_resumo, notifs = [], []\n",
    "    if raw is None:\n",
    "        return casos_resumo, notifs\n",
    "\n",
    "    if isinstance(raw, dict):\n",
    "        for agravo, valor in raw.items():\n",
    "            if isinstance(valor, list) and all(isinstance(i, dict) for i in valor):\n",
    "                total, obitos = 0, 0\n",
    "                for it in valor:\n",
    "                    dt_notific = it.get(\"DT_NOTIFIC\") or it.get(\"_DATA\") or \"\"\n",
    "                    id_unidade = str(it.get(\"ID_UNIDADE\") or \"\")\n",
    "                    dt_nasc = str(it.get(\"DT_NASC\") or \"\")\n",
    "                    cs_sexo = str(it.get(\"CS_SEXO\") or \"\")\n",
    "                    cs_gestant = str(it.get(\"CS_GESTANT\") or \"\")\n",
    "                    cs_raca = str(it.get(\"CS_RACA\") or \"\")\n",
    "                    cs_escol_n = str(it.get(\"CS_ESCOL_N\") or \"\")\n",
    "                    dt_obito = it.get(\"DT_OBITO\") or \"\"\n",
    "\n",
    "                    if not is_valid_date(dt_notific):\n",
    "                        dt_notific = \"\"\n",
    "                    if not is_valid_date(dt_nasc):\n",
    "                        dt_nasc = \"\"\n",
    "                    if is_valid_date(dt_obito):\n",
    "                        obitos += 1\n",
    "                    else:\n",
    "                        dt_obito = \"\"\n",
    "\n",
    "                    props_adicionais = {}\n",
    "                    for k, v in it.items():\n",
    "                        if k in [\n",
    "                            \"DT_NOTIFIC\", \"_DATA\", \"ID_UNIDADE\", \"DT_NASC\",\n",
    "                            \"CS_SEXO\", \"CS_GESTANT\", \"CS_RACA\", \"CS_ESCOL_N\",\n",
    "                            \"DT_OBITO\"\n",
    "                        ]:\n",
    "                            continue\n",
    "                        props_adicionais[k] = sanitize_value(v)\n",
    "                    \n",
    "                    total += 1\n",
    "                    notif_id = f\"{doc_ibge}|{agravo}|{dt_notific}|{id_unidade}|{dt_nasc}|{cs_sexo}\"\n",
    "                    \n",
    "                    notifs.append({\n",
    "                        \"municipio_id\": doc_ibge,\n",
    "                        \"agravo\": agravo,\n",
    "                        \"notif_id\": notif_id,\n",
    "                        \"dt_notific\": dt_notific,\n",
    "                        \"id_unidade\": id_unidade,\n",
    "                        \"dt_nasc\": dt_nasc,\n",
    "                        \"cs_sexo\": cs_sexo,\n",
    "                        \"cs_gestant\": cs_gestant,\n",
    "                        \"cs_raca\": cs_raca,\n",
    "                        \"cs_escol_n\": cs_escol_n,\n",
    "                        \"dt_obito\": dt_obito,\n",
    "                        \"props_adicionais\": props_adicionais\n",
    "                    })\n",
    "                \n",
    "                casos_resumo.append({\n",
    "                    \"municipio_id\": doc_ibge,\n",
    "                    \"agravo\": agravo,\n",
    "                    \"props\": {\"qtd\": total, \"obitos\": obitos}\n",
    "                })\n",
    "    return casos_resumo, notifs\n",
    "\n",
    "def normalize_datas(doc):\n",
    "    datas = []\n",
    "    dct = doc.get(\"datas\") or {}\n",
    "    invalid_dates = 0\n",
    "    \n",
    "    for dt, dia in dct.items():\n",
    "        if not is_valid_date(dt):\n",
    "            invalid_dates += 1\n",
    "            continue\n",
    "            \n",
    "        meteo_map = {}\n",
    "        if \"meteorologia\" in dia:\n",
    "            meteo_map = normalize_meteo_dict(dia[\"meteorologia\"])\n",
    "\n",
    "        ativ = []\n",
    "        for k, itens in dia.items():\n",
    "            if k in (\"meteorologia\", \"casos\", \"cases\", \"sinan\", \"casos_sinan\"):\n",
    "                continue\n",
    "            if str(k).isdigit():\n",
    "                itens = itens if isinstance(itens, list) else [itens]\n",
    "                idx = 0\n",
    "                for it in itens:\n",
    "                    raw_props = {}\n",
    "                    if isinstance(it, dict):\n",
    "                        raw_props = {kk: sanitize_value(vv) for kk, vv in it.items()}\n",
    "                    \n",
    "                    exec_id = f\"{doc['ibge_id']}|{dt}|{k}|{idx}\"\n",
    "                    ativ.append({\n",
    "                        \"exec_id\": exec_id,\n",
    "                        \"municipio_id\": doc[\"ibge_id\"],\n",
    "                        \"tipo\": int(k),\n",
    "                        \"atividade\": (it.get(\"atividade\") or \"\").strip() if isinstance(it, dict) else \"\",\n",
    "                        \"props\": raw_props\n",
    "                    })\n",
    "                    idx += 1\n",
    "        \n",
    "        raw_casos = None\n",
    "        for alias in (\"casos\", \"cases\", \"sinan\", \"casos_sinan\"):\n",
    "            if alias in dia:\n",
    "                raw_casos = dia[alias]\n",
    "                break\n",
    "        \n",
    "        casos_resumo, casos_notifs = normalize_casos(doc[\"ibge_id\"], raw_casos)\n",
    "        \n",
    "        datas.append({\n",
    "            \"dt\": dt,\n",
    "            \"meteo_map\": meteo_map,\n",
    "            \"ativ\": ativ,\n",
    "            \"casos\": casos_resumo,\n",
    "            \"notifs\": casos_notifs\n",
    "        })\n",
    "    \n",
    "    datas.sort(key=lambda r: r[\"dt\"])\n",
    "    \n",
    "    if invalid_dates:\n",
    "        print(f\"  âš ï¸  {invalid_dates} datas invÃ¡lidas ignoradas em {doc.get('ibge_id')}\")\n",
    "    \n",
    "    return datas\n",
    "\n",
    "def build_batches(doc):\n",
    "    geo = doc.get(\"geo_geometry\")\n",
    "    wkt = geojson_to_wkt(geo) if geo else None\n",
    "    lon = lat = None\n",
    "    cent = centroid_from_geojson(geo)\n",
    "    if cent:\n",
    "        lon, lat = cent\n",
    "\n",
    "    datas_norm = normalize_datas(doc)\n",
    "\n",
    "    dias_params = []\n",
    "    meteo_params = []\n",
    "    ativ_params = []\n",
    "    ativ_resumo_counts = {}\n",
    "    casos_params = []\n",
    "    notifs_params = []\n",
    "\n",
    "    for row in datas_norm:\n",
    "        dt = row[\"dt\"]\n",
    "        ibge_id = doc[\"ibge_id\"]\n",
    "\n",
    "        dias_params.append({\"ibge_id\": ibge_id, \"dt\": dt})\n",
    "\n",
    "        if row[\"meteo_map\"]:\n",
    "            meteo_params.append({\n",
    "                \"ibge_id\": ibge_id,\n",
    "                \"dt\": dt,\n",
    "                \"meteo_map\": row[\"meteo_map\"]\n",
    "            })\n",
    "\n",
    "        for at in row[\"ativ\"]:\n",
    "            ativ_params.append({\n",
    "                \"exec_id\": at[\"exec_id\"],\n",
    "                \"dt\": dt,\n",
    "                \"municipio_id\": at[\"municipio_id\"],\n",
    "                \"tipo\": at[\"tipo\"],\n",
    "                \"atividade\": at[\"atividade\"],\n",
    "                \"props\": at[\"props\"] or {}\n",
    "            })\n",
    "            key = (at[\"municipio_id\"], dt, at[\"tipo\"])\n",
    "            ativ_resumo_counts[key] = ativ_resumo_counts.get(key, 0) + 1\n",
    "\n",
    "        for cs in row[\"casos\"]:\n",
    "            casos_params.append({\n",
    "                \"dt\": dt,\n",
    "                \"municipio_id\": cs[\"municipio_id\"],\n",
    "                \"agravo\": cs[\"agravo\"],\n",
    "                \"props\": cs[\"props\"]\n",
    "            })\n",
    "\n",
    "        for nf in row[\"notifs\"]:\n",
    "            notifs_params.append({\n",
    "                \"dt\": dt,\n",
    "                \"municipio_id\": nf[\"municipio_id\"],\n",
    "                \"agravo\": nf[\"agravo\"],\n",
    "                \"notif_id\": nf[\"notif_id\"],\n",
    "                \"dt_notific\": nf[\"dt_notific\"],\n",
    "                \"id_unidade\": nf[\"id_unidade\"],\n",
    "                \"dt_nasc\": nf[\"dt_nasc\"],\n",
    "                \"cs_sexo\": nf[\"cs_sexo\"],\n",
    "                \"cs_gestant\": nf[\"cs_gestant\"],\n",
    "                \"cs_raca\": nf[\"cs_raca\"],\n",
    "                \"cs_escol_n\": nf[\"cs_escol_n\"],\n",
    "                \"dt_obito\": nf[\"dt_obito\"],\n",
    "                \"props_adicionais\": nf[\"props_adicionais\"]\n",
    "            })\n",
    "\n",
    "    ativ_resumo_params = [\n",
    "        {\n",
    "            \"municipio_id\": mid,\n",
    "            \"dt\": dt,\n",
    "            \"tipo\": tipo,\n",
    "            \"qtd_execucoes\": qtd\n",
    "        }\n",
    "        for (mid, dt, tipo), qtd in ativ_resumo_counts.items()\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"municipio_payload\": {\n",
    "            \"ibge_id\": doc[\"ibge_id\"],\n",
    "            \"nome\": doc.get(\"municipio_nome\"),\n",
    "            \"sisaweb_id\": doc.get(\"sisaweb_id\"),\n",
    "            \"geojson_str\": json.dumps(geo, ensure_ascii=False) if geo else None,\n",
    "            \"wkt\": wkt,\n",
    "            \"lon\": lon,\n",
    "            \"lat\": lat\n",
    "        },\n",
    "        \"dias_params\": dias_params,\n",
    "        \"meteo_params\": meteo_params,\n",
    "        \"ativ_params\": ativ_params,\n",
    "        \"ativ_resumo_params\": ativ_resumo_params,\n",
    "        \"casos_params\": casos_params,\n",
    "        \"notifs_params\": notifs_params\n",
    "    }\n",
    "\n",
    "def run_chunked(connection_mgr, query, data_list, param_name, chunk_size=SAFE_CHUNK_SIZE):\n",
    "    if not data_list:\n",
    "        return\n",
    "\n",
    "    with connection_mgr.get_session() as session:\n",
    "        for i in range(0, len(data_list), chunk_size):\n",
    "            sub = data_list[i:i + chunk_size]\n",
    "            if not sub:\n",
    "                continue\n",
    "            with session.begin_transaction() as tx:\n",
    "                tx.run(query, **{param_name: sub})\n",
    "                tx.commit()\n",
    "\n",
    "def _total_records_from_batches(b):\n",
    "    return (\n",
    "        len(b[\"dias_params\"]) +\n",
    "        len(b[\"meteo_params\"]) +\n",
    "        len(b[\"ativ_params\"]) +\n",
    "        len(b[\"ativ_resumo_params\"]) +\n",
    "        len(b[\"casos_params\"]) +\n",
    "        len(b[\"notifs_params\"])\n",
    "    )\n",
    "\n",
    "def process_one_file_fast(connection_mgr, doc, prebuilt=None):\n",
    "    b = prebuilt if prebuilt is not None else build_batches(doc)\n",
    "\n",
    "    total_records = _total_records_from_batches(b)\n",
    "    print(f\"  âš¡ [FAST] MunicÃ­pio {doc['ibge_id']} - {total_records} registros (transaÃ§Ã£o Ãºnica)\")\n",
    "\n",
    "    with connection_mgr.get_session() as session:\n",
    "        with session.begin_transaction() as tx:\n",
    "            tx.run(CYPHER_UPSERT_MUNICIPIO, **b[\"municipio_payload\"])\n",
    "            if b[\"dias_params\"]:\n",
    "                tx.run(CYPHER_BULK_DIAS, dias=b[\"dias_params\"])\n",
    "            if b[\"meteo_params\"]:\n",
    "                tx.run(CYPHER_BULK_METEO, met=b[\"meteo_params\"])\n",
    "            if b[\"ativ_params\"]:\n",
    "                tx.run(CYPHER_BULK_ATIV, ativ=b[\"ativ_params\"])\n",
    "            if b[\"ativ_resumo_params\"]:\n",
    "                tx.run(CYPHER_BULK_ATIV_RESUMO, resumos=b[\"ativ_resumo_params\"])\n",
    "                tx.run(CYPHER_LINK_ATIV_RESUMO, resumos=b[\"ativ_resumo_params\"])\n",
    "            if b[\"casos_params\"]:\n",
    "                tx.run(CYPHER_BULK_CASOS, casos=b[\"casos_params\"])\n",
    "            if b[\"notifs_params\"]:\n",
    "                tx.run(CYPHER_BULK_NOTIFS, notifs=b[\"notifs_params\"])\n",
    "            tx.commit()\n",
    "\n",
    "def process_one_file_chunked(connection_mgr, doc, prebuilt=None):\n",
    "    b = prebuilt if prebuilt is not None else build_batches(doc)\n",
    "\n",
    "    total_records = _total_records_from_batches(b)\n",
    "    print(f\"  ðŸ›¡ï¸ [SAFE] MunicÃ­pio {doc['ibge_id']} - {total_records} registros \"\n",
    "          f\"(chunked, {SAFE_CHUNK_SIZE} por batch)\")\n",
    "\n",
    "    with connection_mgr.get_session() as session:\n",
    "        with session.begin_transaction() as tx:\n",
    "            tx.run(CYPHER_UPSERT_MUNICIPIO, **b[\"municipio_payload\"])\n",
    "            tx.commit()\n",
    "\n",
    "    if b[\"dias_params\"]:\n",
    "        with connection_mgr.get_session() as session:\n",
    "            with session.begin_transaction() as tx:\n",
    "                tx.run(CYPHER_BULK_DIAS, dias=b[\"dias_params\"])\n",
    "                tx.commit()\n",
    "\n",
    "    if b[\"meteo_params\"]:\n",
    "        run_chunked(connection_mgr, CYPHER_BULK_METEO, b[\"meteo_params\"], \"met\")\n",
    "\n",
    "    if b[\"ativ_params\"]:\n",
    "        run_chunked(connection_mgr, CYPHER_BULK_ATIV, b[\"ativ_params\"], \"ativ\")\n",
    "\n",
    "    if b[\"ativ_resumo_params\"]:\n",
    "        run_chunked(connection_mgr, CYPHER_BULK_ATIV_RESUMO, b[\"ativ_resumo_params\"], \"resumos\")\n",
    "        run_chunked(connection_mgr, CYPHER_LINK_ATIV_RESUMO, b[\"ativ_resumo_params\"], \"resumos\")\n",
    "\n",
    "    if b[\"casos_params\"]:\n",
    "        run_chunked(connection_mgr, CYPHER_BULK_CASOS, b[\"casos_params\"], \"casos\")\n",
    "\n",
    "    if b[\"notifs_params\"]:\n",
    "        run_chunked(connection_mgr, CYPHER_BULK_NOTIFS, b[\"notifs_params\"], \"notifs\")\n",
    "\n",
    "\n",
    "def load_progress(path):\n",
    "    if not os.path.exists(path):\n",
    "        return set()\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return {l.strip() for l in f if l.strip()}\n",
    "\n",
    "def append_progress(path, fname):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(fname + \"\\n\")\n",
    "\n",
    "def main():\n",
    "\n",
    "    db_manager = Neo4jDatabaseManager(NEO4J_URI, NEO4J_USER, NEO4J_PASS, NEO4J_DB)\n",
    "    \n",
    "    if not db_manager.ensure_database_exists():\n",
    "        return\n",
    "    \n",
    "    connection_mgr = Neo4jConnectionManager(NEO4J_URI, NEO4J_USER, NEO4J_PASS, NEO4J_DB)\n",
    "    \n",
    "    try:\n",
    "        with connection_mgr.get_session() as sess:\n",
    "            for c in CYPHER_CONSTRAINTS:\n",
    "                try:\n",
    "                    sess.run(c)\n",
    "                except ClientError as e:\n",
    "                    print(f\"Aviso constraint: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao criar/verificar constraint: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        connection_mgr.close()\n",
    "        db_manager.close()\n",
    "        return\n",
    "\n",
    "    files = sorted(glob.glob(FOLDER_JSONS))\n",
    "    if not files:\n",
    "        raise SystemExit(f\"Nenhum JSON em {FOLDER_JSONS}\")\n",
    "    \n",
    "    done = load_progress(PROGRESS_FILE)\n",
    "    ok = falha = 0\n",
    "\n",
    "    for fp in files:\n",
    "        base = os.path.basename(fp)\n",
    "        if base in done:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        try:\n",
    "            with open(fp, \"r\", encoding=\"utf-8\") as f:\n",
    "                doc = json.load(f)\n",
    "\n",
    "            batches = build_batches(doc)\n",
    "            total_records = _total_records_from_batches(batches)\n",
    "\n",
    "            sucesso = False\n",
    "\n",
    "            if total_records <= MAX_FAST_RECORDS:\n",
    "                try:\n",
    "                    process_one_file_fast(connection_mgr, doc, prebuilt=batches)\n",
    "                    sucesso = True\n",
    "                except Exception as e_fast:\n",
    "                    try:\n",
    "                        process_one_file_chunked(connection_mgr, doc, prebuilt=batches)\n",
    "                        sucesso = True\n",
    "                    except Exception as e_safe:\n",
    "                        sucesso = False\n",
    "            else:\n",
    "                try:\n",
    "                    process_one_file_chunked(connection_mgr, doc, prebuilt=batches)\n",
    "                    sucesso = True\n",
    "                except Exception as e_safe:\n",
    "                    sucesso = False\n",
    "            \n",
    "            if sucesso:\n",
    "                append_progress(PROGRESS_FILE, base)\n",
    "                ok += 1\n",
    "            else:\n",
    "                falha += 1\n",
    "\n",
    "        except Exception as e_outer:\n",
    "            falha += 1\n",
    "\n",
    "    try:\n",
    "        with connection_mgr.get_session() as sess:\n",
    "            r1 = sess.run(\"MATCH (m:Municipio) RETURN count(m) AS n\").single()[\"n\"]\n",
    "            r2 = sess.run(\"MATCH (d:Dia) RETURN count(d) AS n\").single()[\"n\"]\n",
    "            r3 = sess.run(\"MATCH (c:Casos) RETURN count(c) AS n\").single()[\"n\"]\n",
    "            r4 = sess.run(\"MATCH (n:Notificacao) RETURN count(n) AS n\").single()[\"n\"]\n",
    "            rA = sess.run(\"MATCH (a:AtividadeExec) RETURN count(a) AS n\").single()[\"n\"]\n",
    "            rT = sess.run(\"MATCH (t:TipoAtividade) RETURN count(t) AS n\").single()[\"n\"]\n",
    "            rG = sess.run(\"MATCH (g:Agravo) RETURN count(g) AS n\").single()[\"n\"]\n",
    "            rAR = sess.run(\"MATCH (ar:AtividadeResumo) RETURN count(ar) AS n\").single()[\"n\"]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao obter mÃ©tricas finais: {e}\")\n",
    "\n",
    "    connection_mgr.close()\n",
    "    db_manager.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
